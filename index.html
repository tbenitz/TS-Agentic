<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LiquidAI LFM2.5 - WebGPU Native</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" />
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        body { background-color: #000000; color: #e2e8f0; font-family: 'Inter', system-ui, sans-serif; }
        
        /* Chat UI */
        .chat-bubble { max-width: 90%; padding: 16px; border-radius: 16px; margin-bottom: 24px; line-height: 1.7; position: relative; }
        .user-bubble { background-color: #252525; color: #fff; align-self: flex-end; border-bottom-right-radius: 4px; }
        .ai-bubble { background-color: #0a0a0a; border: 1px solid #333; align-self: flex-start; border-bottom-left-radius: 4px; padding-top: 30px; }
        .ai-bubble::before { content: 'LFM2.5'; position: absolute; top: -10px; left: 10px; font-size: 0.7rem; background: #000; padding: 2px 8px; border: 1px solid #333; color: #888; border-radius: 4px; }
        
        /* Thinking Process */
        .thinking-box { border-left: 2px solid #4f46e5; background: #1e1b4b20; padding: 8px 12px; margin: 8px 0; font-size: 0.9em; color: #a5b4fc; font-family: monospace; display: none; }
        .thinking-box.active { display: block; }

        /* Progress Overlay */
        #progress-container { 
            position: fixed; top: 0; left: 0; width: 100%; height: 100%; 
            background: #000000; 
            display: flex; justify-content: center; align-items: center; 
            z-index: 100; flex-direction: column; 
        }
        .liquid-loader {
            width: 60px; height: 60px; border-radius: 50%;
            background: conic-gradient(#0000 10%, #4f46e5);
            -webkit-mask: radial-gradient(farthest-side,#0000 calc(100% - 8px),#000 0);
            animation: spin 1s infinite linear;
            margin-bottom: 20px;
        }
        @keyframes spin {to{transform: rotate(1turn)}}
        
        /* Code Blocks */
        pre { background: #111; padding: 15px; border-radius: 8px; overflow-x: auto; border: 1px solid #333; margin: 10px 0; }
        code { font-family: 'JetBrains Mono', monospace; font-size: 0.85em; }
    </style>
</head>
<body class="h-screen flex flex-col overflow-hidden">

    <header class="bg-black border-b border-white/10 p-4 shrink-0 flex justify-between items-center z-20">
        <div class="flex items-center gap-3">
            <div class="w-2 h-2 rounded-full bg-indigo-500 shadow-[0_0_10px_#4f46e5]"></div>
            <h1 class="text-lg font-medium tracking-wide text-white">Liquid<span class="text-indigo-500">AI</span> LFM2.5</h1>
        </div>
        
        <button onclick="document.getElementById('settings-panel').classList.toggle('hidden')" class="text-xs text-gray-500 hover:text-white transition">
            <i class="fas fa-cog"></i> Config
        </button>
    </header>

    <div id="settings-panel" class="hidden bg-neutral-900 border-b border-white/10 p-4 text-xs text-gray-400 absolute w-full top-14 z-10 shadow-2xl">
        <div class="max-w-2xl mx-auto space-y-3">
            <div class="flex flex-col gap-1">
                <label>Hugging Face Model ID (LiquidAI)</label>
                <input type="text" id="model-id-input" value="LiquidAI/LFM2.5-1.2B-Thinking-ONNX" class="bg-black border border-white/20 p-2 rounded text-white w-full">
                <p class="text-[10px] text-gray-600">Note: If standard loading fails, ensure the model has `model_q4.onnx` or similar in the repo.</p>
            </div>
            <div class="flex flex-col gap-1">
                <label>HF Token (Optional - for gated models)</label>
                <input type="password" id="hf-token-input" placeholder="hf_..." class="bg-black border border-white/20 p-2 rounded text-white w-full">
            </div>
            <button onclick="window.location.reload()" class="bg-indigo-600 text-white px-3 py-1 rounded hover:bg-indigo-500">Apply & Reload</button>
        </div>
    </div>

    <main class="flex-1 overflow-y-auto p-4 scroll-smooth" id="chat-container">
        <div class="max-w-3xl mx-auto flex flex-col justify-end min-h-full pb-4" id="messages">
            </div>
    </main>

    <footer class="p-4 bg-black border-t border-white/10 shrink-0">
        <div class="max-w-3xl mx-auto relative group">
            <textarea id="user-input" rows="1" class="w-full bg-[#111] border border-[#333] rounded-2xl py-4 px-5 pr-14 focus:ring-1 focus:ring-indigo-500 focus:outline-none text-white resize-none shadow-lg transition-all" placeholder="Message LiquidAI..." oninput="this.style.height = ''; this.style.height = this.scrollHeight + 'px'" onkeydown="handleEnter(event)"></textarea>
            <button id="send-btn" class="absolute right-3 bottom-3 text-indigo-500 hover:text-white transition p-2">
                <i class="fas fa-arrow-up"></i>
            </button>
        </div>
        <div class="text-center mt-2">
            <span class="text-[10px] text-gray-700">Runs locally in browser (WebGPU) â€¢ 1.2GB Download on first run</span>
        </div>
    </footer>

    <div id="progress-container" class="hidden">
        <div class="liquid-loader"></div>
        <div class="text-xl font-light text-white mb-1" id="progress-title">Initializing Liquid Engine</div>
        <div class="text-xs text-indigo-400 font-mono mb-4" id="progress-filename">Connecting...</div>
        
        <div class="w-64 h-1 bg-gray-900 rounded overflow-hidden">
            <div id="progress-bar-fill" class="h-full bg-indigo-600 w-0 transition-all duration-100"></div>
        </div>
        <div id="progress-stats" class="text-[10px] text-gray-600 mt-2 font-mono">0%</div>
        
        <div id="error-log" class="hidden mt-6 p-4 bg-red-900/10 border border-red-900/50 rounded text-red-400 text-xs font-mono max-w-lg whitespace-pre-wrap text-left"></div>
    </div>

    <script id="worker-code" type="javascript/worker">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.2.4';

        // FORCE CONFIGURATION
        env.allowLocalModels = false;
        env.useBrowserCache = true;
        
        // This disables the "HEAD" check that often fails on CORS for some HF repos
        env.useCustomCache = true; 

        let generator = null;

        self.onmessage = async (event) => {
            const { type, data } = event.data;

            if (type === 'init') {
                try {
                    const { modelId, token } = data;
                    
                    if (token) env.token = token;

                    self.postMessage({ type: 'status', text: 'Fetching model manifest...' });

                    // Progress callback
                    const progressCallback = (info) => {
                        self.postMessage({ 
                            type: 'progress', 
                            file: info.file, 
                            status: info.status,
                            progress: info.progress 
                        });
                    };

                    // Initialize Pipeline
                    // "LiquidAI/LFM2.5-1.2B-Thinking-ONNX"
                    // We force dtype "q4" to ensure it grabs the quantized version if available
                    // We also specify "webgpu" explicitly.
                    
                    generator = await pipeline('text-generation', modelId, {
                        device: 'webgpu',
                        dtype: 'q4', 
                        progress_callback: progressCallback,
                        
                        // Critical: Some Liquid models need specific file names. 
                        // If this fails, we might need to specify { model: 'onnx/model_q4.onnx' } revision
                    });

                    self.postMessage({ type: 'ready' });

                } catch (err) {
                    self.postMessage({ type: 'error', message: err.toString() + "\n" + (err.stack || "") });
                }
            } 

            if (type === 'generate') {
                if (!generator) return;

                const messages = data.messages;
                self.postMessage({ type: 'start' });

                try {
                    // Chat Template
                    const prompt = await generator.tokenizer.apply_chat_template(messages, {
                        add_generation_prompt: true,
                        tokenize: false
                    });

                    // Generation
                    const output = await generator(prompt, {
                        max_new_tokens: 1024,
                        temperature: 0.6,
                        top_p: 0.9,
                        do_sample: true,
                        callback_function: (beams) => {
                            const decodedText = generator.tokenizer.decode(beams[0].output_token_ids, { skip_special_tokens: true });
                            self.postMessage({ type: 'stream', text: decodedText });
                        }
                    });

                    self.postMessage({ type: 'done', output: output[0].generated_text });

                } catch (err) {
                    self.postMessage({ type: 'error', message: err.toString() });
                }
            }
        };
    </script>

    <script type="module">
        // --- Setup Worker ---
        const workerBlob = new Blob([document.getElementById('worker-code').textContent], { type: 'application/javascript' });
        const worker = new Worker(URL.createObjectURL(workerBlob), { type: 'module' });

        // --- State ---
        const ui = {
            chat: document.getElementById('messages'),
            input: document.getElementById('user-input'),
            sendBtn: document.getElementById('send-btn'),
            overlay: document.getElementById('progress-container'),
            pTitle: document.getElementById('progress-title'),
            pFile: document.getElementById('progress-filename'),
            pBar: document.getElementById('progress-bar-fill'),
            pStats: document.getElementById('progress-stats'),
            errorLog: document.getElementById('error-log'),
            modelIdInput: document.getElementById('model-id-input'),
            tokenInput: document.getElementById('hf-token-input')
        };

        let state = {
            ready: false,
            history: [],
            currentBubble: null,
            pendingMsg: null
        };

        // --- Worker Handling ---
        worker.onmessage = (e) => {
            const { type, file, status, progress, message, text, output } = e.data;

            if (type === 'progress') {
                ui.overlay.classList.remove('hidden');
                if (file) {
                    ui.pFile.innerText = file;
                    const pct = Math.round(progress || 0);
                    ui.pBar.style.width = pct + "%";
                    ui.pStats.innerText = pct + "%";
                }
            }

            if (type === 'status') {
                ui.overlay.classList.remove('hidden');
                ui.pTitle.innerText = message;
            }

            if (type === 'ready') {
                state.ready = true;
                ui.overlay.classList.add('hidden');
                if (state.pendingMsg) sendToWorker(state.pendingMsg);
            }

            if (type === 'start') {
                const bubble = document.createElement('div');
                bubble.className = 'ai-bubble chat-bubble';
                bubble.innerHTML = '<span class="text-indigo-400 animate-pulse">Thinking...</span>';
                ui.chat.appendChild(bubble);
                state.currentBubble = bubble;
                scrollToBottom();
            }

            if (type === 'stream') {
                const cleanText = extractResponse(text);
                state.currentBubble.innerHTML = parseMarkdown(cleanText);
                scrollToBottom();
            }

            if (type === 'done') {
                const cleanText = extractResponse(output);
                state.currentBubble.innerHTML = parseMarkdown(cleanText);
                state.history.push({ role: 'assistant', content: cleanText });
                ui.input.value = '';
                ui.input.disabled = false;
                ui.input.focus();
                scrollToBottom();
            }

            if (type === 'error') {
                ui.overlay.classList.remove('hidden');
                ui.pTitle.innerText = "Error";
                ui.pTitle.classList.add('text-red-500');
                ui.errorLog.classList.remove('hidden');
                ui.errorLog.innerText = message;
                
                // Friendly advice based on common errors
                if (message.includes('404') || message.includes('undefined')) {
                     ui.errorLog.innerText += "\n\n[POSSIBLE FIX]: The Model ID might be wrong or the repo is private. Try checking the Settings (top right) and entering a Hugging Face Token.";
                }
            }
        };

        // --- Core Functions ---
        
        function initModel() {
            const modelId = ui.modelIdInput.value.trim();
            const token = ui.tokenInput.value.trim();
            ui.overlay.classList.remove('hidden');
            worker.postMessage({ type: 'init', data: { modelId, token } });
        }

        function sendToWorker(messages) {
            worker.postMessage({ type: 'generate', data: { messages } });
            state.pendingMsg = null;
        }

        function extractResponse(fullText) {
            // Strip system prompts and user inputs from LFM/Llama formats
            let clean = fullText;
            const markers = ['[/INST]', '<|im_start|>assistant', '<|start_header_id|>assistant<|end_header_id|>'];
            
            for (const m of markers) {
                if (clean.includes(m)) {
                    clean = clean.split(m).pop();
                }
            }
            return clean.trim();
        }

        function parseMarkdown(text) {
            // Use marked.js if available, else fallback
            if (typeof marked !== 'undefined') {
                return marked.parse(text);
            }
            return text.replace(/\n/g, '<br>');
        }

        function scrollToBottom() {
            const main = document.querySelector('main');
            main.scrollTop = main.scrollHeight;
        }

        // --- Interaction ---
        
        ui.sendBtn.addEventListener('click', () => {
            const text = ui.input.value.trim();
            if (!text) return;

            // Add User Bubble
            const bubble = document.createElement('div');
            bubble.className = 'user-bubble chat-bubble';
            bubble.innerText = text;
            ui.chat.appendChild(bubble);
            scrollToBottom();

            // Prepare History
            // We only send the last few turns to keep context window manageable for browser
            const newHistory = [...state.history, { role: 'user', content: text }];
            state.history = newHistory;

            ui.input.disabled = true;

            if (!state.ready) {
                state.pendingMsg = newHistory;
                initModel();
            } else {
                sendToWorker(newHistory);
            }
        });

        window.handleEnter = (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                ui.sendBtn.click();
            }
        }
    </script>
</body>
</html>
